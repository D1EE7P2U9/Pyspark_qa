from pyspark.sql import SparkSession
from pyspark.sql import Window
from pyspark.sql.functions import col, dense_rank , row_number , rank
from pyspark.sql.types import StructType, StructField, IntegerType, StringType

spark = SparkSession.builder.appName('ranks').getOrCreate()

#create data
emp_data = [
 (101, "Varun", "Sales", 75000),
 (102, "Alia", "HR", 46000),
 (103, "David", "IT", 55000),
 (104, "Steve", "Sales", 75000),
 (105, "Soham", "HR", 46000),
 (106, "Kiron", "IT", 50000),
 (107, "Dhoni", "Sales", 68000),
 (108, "Tiger", "HR", 45000),
 (109, "Rock", "IT", 53000),
 (110, "Khali", "Sales", 75000)
]

#schema of the data
emp_schema = StructType([
 StructField("EmployeeID", IntegerType(), True),
 StructField("Name", StringType(), True),
 StructField("Department", StringType(), True),
 StructField("Salary", IntegerType(), True)
])

#create dataframe from the data and schema
emp_data = spark.createDataFrame(data = emp_data , schema = emp_schema)

#displaying the created dataframe
emp_data.show()

#create the window specifications
window_spec = Window.partitionBy(col('Department')).orderBy(col('Salary').desc())

#create the dataframe with additional columns with rank , row_number , dense_rank
df = emp_data.withColumn('row_number',row_number().over(window_spec)).\
    withColumn('rank',rank().over(window_spec)).\
        withColumn('dense_rank',dense_rank().over(window_spec))

#display the dataframe to observe how rank , row_number , dense_rank behave.
df.show()
